{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wBUh0EiJrt2d"
      },
      "source": [
        "# Latent-NeRF"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i0eutuh3rt2e"
      },
      "source": [
        "## 0. Setup Environment"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/vain05/latent-nerf.git\n",
        "%cd /content/latent-nerf\n",
        "%pip install -r requirements.txt"
      ],
      "metadata": {
        "id": "HFz3t5SLuXyq",
        "outputId": "fa03c33d-a171-4df1-cb49-bb5dd6bada6f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'latent-nerf'...\n",
            "remote: Enumerating objects: 9, done.\u001b[K\n",
            "remote: Counting objects: 100% (9/9), done.\u001b[K\n",
            "remote: Compressing objects: 100% (6/6), done.\u001b[K\n",
            "remote: Total 9 (delta 1), reused 9 (delta 1), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (9/9), 1.09 KiB | 560.00 KiB/s, done.\n",
            "/content/latent-nerf\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: torch==1.13.1 in /usr/local/lib/python3.9/dist-packages (from -r requirements.txt (line 1)) (1.13.1+cu116)\n",
            "Requirement already satisfied: torchvision==0.14.1 in /usr/local/lib/python3.9/dist-packages (from -r requirements.txt (line 2)) (0.14.1+cu116)\n",
            "Collecting transformers\n",
            "  Downloading transformers-4.26.1-py3-none-any.whl (6.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.3/6.3 MB\u001b[0m \u001b[31m85.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting diffusers\n",
            "  Downloading diffusers-0.14.0-py3-none-any.whl (737 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m737.4/737.4 KB\u001b[0m \u001b[31m57.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting accelerate\n",
            "  Downloading accelerate-0.16.0-py3-none-any.whl (199 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m199.7/199.7 KB\u001b[0m \u001b[31m29.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting huggingface-hub\n",
            "  Downloading huggingface_hub-0.13.1-py3-none-any.whl (199 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m199.2/199.2 KB\u001b[0m \u001b[31m28.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting ninja\n",
            "  Downloading ninja-1.11.1-py2.py3-none-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (145 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m146.0/146.0 KB\u001b[0m \u001b[31m19.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting xatlas\n",
            "  Downloading xatlas-0.0.7-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (229 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m229.5/229.5 KB\u001b[0m \u001b[31m33.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: imageio in /usr/local/lib/python3.9/dist-packages (from -r requirements.txt (line 9)) (2.9.0)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.9/dist-packages (from -r requirements.txt (line 10)) (3.5.3)\n",
            "Collecting pyrallis\n",
            "  Downloading pyrallis-0.3.1-py3-none-any.whl (33 kB)\n",
            "Collecting loguru\n",
            "  Downloading loguru-0.6.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 KB\u001b[0m \u001b[31m10.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.9/dist-packages (from -r requirements.txt (line 13)) (4.65.0)\n",
            "Collecting libigl\n",
            "  Downloading libigl-2.4.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.6/13.6 MB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.9/dist-packages (from torch==1.13.1->-r requirements.txt (line 1)) (4.5.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.9/dist-packages (from torchvision==0.14.1->-r requirements.txt (line 2)) (2.25.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.9/dist-packages (from torchvision==0.14.1->-r requirements.txt (line 2)) (1.22.4)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.9/dist-packages (from torchvision==0.14.1->-r requirements.txt (line 2)) (8.4.0)\n",
            "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1\n",
            "  Downloading tokenizers-0.13.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.6/7.6 MB\u001b[0m \u001b[31m100.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.9/dist-packages (from transformers->-r requirements.txt (line 3)) (6.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.9/dist-packages (from transformers->-r requirements.txt (line 3)) (3.9.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.9/dist-packages (from transformers->-r requirements.txt (line 3)) (2022.6.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.9/dist-packages (from transformers->-r requirements.txt (line 3)) (23.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.9/dist-packages (from diffusers->-r requirements.txt (line 4)) (6.0.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.9/dist-packages (from accelerate->-r requirements.txt (line 5)) (5.4.8)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib->-r requirements.txt (line 10)) (4.39.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.9/dist-packages (from matplotlib->-r requirements.txt (line 10)) (1.4.4)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.9/dist-packages (from matplotlib->-r requirements.txt (line 10)) (2.8.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.9/dist-packages (from matplotlib->-r requirements.txt (line 10)) (0.11.0)\n",
            "Requirement already satisfied: pyparsing>=2.2.1 in /usr/local/lib/python3.9/dist-packages (from matplotlib->-r requirements.txt (line 10)) (3.0.9)\n",
            "Collecting typing-inspect\n",
            "  Downloading typing_inspect-0.8.0-py3-none-any.whl (8.7 kB)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.9/dist-packages (from libigl->-r requirements.txt (line 14)) (1.10.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.9/dist-packages (from python-dateutil>=2.7->matplotlib->-r requirements.txt (line 10)) (1.15.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.9/dist-packages (from importlib-metadata->diffusers->-r requirements.txt (line 4)) (3.15.0)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.9/dist-packages (from requests->torchvision==0.14.1->-r requirements.txt (line 2)) (4.0.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests->torchvision==0.14.1->-r requirements.txt (line 2)) (1.26.14)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests->torchvision==0.14.1->-r requirements.txt (line 2)) (2022.12.7)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests->torchvision==0.14.1->-r requirements.txt (line 2)) (2.10)\n",
            "Collecting mypy-extensions>=0.3.0\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Installing collected packages: xatlas, tokenizers, ninja, mypy-extensions, loguru, typing-inspect, libigl, huggingface-hub, accelerate, transformers, pyrallis, diffusers\n",
            "Successfully installed accelerate-0.16.0 diffusers-0.14.0 huggingface-hub-0.13.1 libigl-2.4.1 loguru-0.6.0 mypy-extensions-1.0.0 ninja-1.11.1 pyrallis-0.3.1 tokenizers-0.13.2 transformers-4.26.1 typing-inspect-0.8.0 xatlas-0.0.7\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content\n",
        "%rm -rf latent-nerf"
      ],
      "metadata": {
        "id": "MTCRE93txITt",
        "outputId": "958b8396-aef8-4c5b-8079-2e5f629d9d12",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "Oy3lqTmirt2f",
        "outputId": "173cf3df-b962-4877-bc73-0157cbfa352a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'latent-nerf'...\n",
            "remote: Enumerating objects: 163, done.\u001b[K\n",
            "remote: Counting objects: 100% (33/33), done.\u001b[K\n",
            "remote: Compressing objects: 100% (27/27), done.\u001b[K\n",
            "remote: Total 163 (delta 11), reused 6 (delta 6), pack-reused 130\u001b[K\n",
            "Receiving objects: 100% (163/163), 78.87 MiB | 4.76 MiB/s, done.\n",
            "Resolving deltas: 100% (38/38), done.\n",
            "/content/latent-nerf\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/eladrich/latent-nerf.git\n",
        "%cd /content/latent-nerf"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!huggingface-cli login"
      ],
      "metadata": {
        "id": "Bo0iDzkrxgyS",
        "outputId": "21a666ed-5229-44de-fb3a-f64b9699be38",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "    _|    _|  _|    _|    _|_|_|    _|_|_|  _|_|_|  _|      _|    _|_|_|      _|_|_|_|    _|_|      _|_|_|  _|_|_|_|\n",
            "    _|    _|  _|    _|  _|        _|          _|    _|_|    _|  _|            _|        _|    _|  _|        _|\n",
            "    _|_|_|_|  _|    _|  _|  _|_|  _|  _|_|    _|    _|  _|  _|  _|  _|_|      _|_|_|    _|_|_|_|  _|        _|_|_|\n",
            "    _|    _|  _|    _|  _|    _|  _|    _|    _|    _|    _|_|  _|    _|      _|        _|    _|  _|        _|\n",
            "    _|    _|    _|_|      _|_|_|    _|_|_|  _|_|_|  _|      _|    _|_|_|      _|        _|    _|    _|_|_|  _|_|_|_|\n",
            "    \n",
            "    To login, `huggingface_hub` requires a token generated from https://huggingface.co/settings/tokens .\n",
            "Token: \n",
            "Add token as git credential? (Y/n) n\n",
            "Token is valid.\n",
            "Your token has been saved to /root/.cache/huggingface/token\n",
            "Login successful\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cat /root/.cache/huggingface/token > /content/latent-nerf/TOKEN"
      ],
      "metadata": {
        "id": "9j6Gd8I5ybdp",
        "outputId": "1b2b38ce-1f4e-4585-9186-9e38af5b6ddf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "try:\n",
        "    import kaolin\n",
        "except:\n",
        "    %pip install kaolin==0.13.0 -f https://nvidia-kaolin.s3.us-east-2.amazonaws.com/torch-1.13.1_cu116.html\n",
        "    import os\n",
        "    os.kill(os.getpid(), 9)"
      ],
      "metadata": {
        "id": "MnM7NzpBvh2x",
        "outputId": "c845e06d-3f1d-49d1-977c-f0a28895d1a2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Looking in links: https://nvidia-kaolin.s3.us-east-2.amazonaws.com/torch-1.13.1_cu116.html\n",
            "Collecting kaolin==0.13.0\n",
            "  Downloading https://nvidia-kaolin.s3.us-east-2.amazonaws.com/torch-1.13.1_cu116/kaolin-0.13.0-cp39-cp39-linux_x86_64.whl (3.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.8/3.8 MB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting flask==2.0.3\n",
            "  Downloading Flask-2.0.3-py3-none-any.whl (95 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m95.6/95.6 KB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tornado==6.1\n",
            "  Downloading tornado-6.1-cp39-cp39-manylinux2010_x86_64.whl (427 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m427.2/427.2 KB\u001b[0m \u001b[31m35.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting usd-core<22.8\n",
            "  Downloading usd_core-22.5.post1-cp39-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (24.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.3/24.3 MB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: Pillow>=8.0.0 in /usr/local/lib/python3.9/dist-packages (from kaolin==0.13.0) (8.4.0)\n",
            "Requirement already satisfied: scipy>=1.2.0 in /usr/local/lib/python3.9/dist-packages (from kaolin==0.13.0) (1.10.1)\n",
            "Requirement already satisfied: tqdm>=4.51.0 in /usr/local/lib/python3.9/dist-packages (from kaolin==0.13.0) (4.65.0)\n",
            "Requirement already satisfied: Werkzeug>=2.0 in /usr/local/lib/python3.9/dist-packages (from flask==2.0.3->kaolin==0.13.0) (2.2.3)\n",
            "Requirement already satisfied: itsdangerous>=2.0 in /usr/local/lib/python3.9/dist-packages (from flask==2.0.3->kaolin==0.13.0) (2.1.2)\n",
            "Requirement already satisfied: Jinja2>=3.0 in /usr/local/lib/python3.9/dist-packages (from flask==2.0.3->kaolin==0.13.0) (3.1.2)\n",
            "Requirement already satisfied: click>=7.1.2 in /usr/local/lib/python3.9/dist-packages (from flask==2.0.3->kaolin==0.13.0) (8.1.3)\n",
            "Requirement already satisfied: numpy<1.27.0,>=1.19.5 in /usr/local/lib/python3.9/dist-packages (from scipy>=1.2.0->kaolin==0.13.0) (1.22.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.9/dist-packages (from Jinja2>=3.0->flask==2.0.3->kaolin==0.13.0) (2.1.2)\n",
            "Installing collected packages: usd-core, tornado, flask, kaolin\n",
            "  Attempting uninstall: tornado\n",
            "    Found existing installation: tornado 6.2\n",
            "    Uninstalling tornado-6.2:\n",
            "      Successfully uninstalled tornado-6.2\n",
            "  Attempting uninstall: flask\n",
            "    Found existing installation: Flask 2.2.3\n",
            "    Uninstalling Flask-2.2.3:\n",
            "      Successfully uninstalled Flask-2.2.3\n",
            "Successfully installed flask-2.0.3 kaolin-0.13.0 tornado-6.1 usd-core-22.5.post1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Text Guided Generation"
      ],
      "metadata": {
        "id": "qp5OrzgOwIXe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/latent-nerf/"
      ],
      "metadata": {
        "id": "bc12zx_dzNxL",
        "outputId": "36175608-1e56-400b-ac26-4e69480d3992",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/latent-nerf\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install imageio-ffmpeg"
      ],
      "metadata": {
        "id": "Xz6rFV5YDcSC",
        "outputId": "2bcdec4e-1b64-4a1e-8d3c-68f92859cfc8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting imageio-ffmpeg\n",
            "  Downloading imageio_ffmpeg-0.4.8-py3-none-manylinux2010_x86_64.whl (26.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m26.9/26.9 MB\u001b[0m \u001b[31m56.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: imageio-ffmpeg\n",
            "Successfully installed imageio-ffmpeg-0.4.8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python -m scripts.train_latent_nerf --log.exp_name 'sand_castle' --guide.text 'a highly detailed sand castle' --render.nerf_type latent"
      ],
      "metadata": {
        "id": "1lreGS02wHeS",
        "outputId": "88c91571-60eb-4612-f12e-b42ae5f0be95",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-03-09 14:47:39.344153: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
            "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2023-03-09 14:47:40.212606: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-09 14:47:40.212706: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-09 14:47:40.212725: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "\u001b[32m2023-03-09 14:47:44\u001b[0m \u001b[1mLoading CUDA ray marching module (compiling might take a while)...\u001b[0m\n",
            "\u001b[32m2023-03-09 14:50:17\u001b[0m \u001b[1m\tDone.\u001b[0m\n",
            "\u001b[32m2023-03-09 14:50:18\u001b[0m \u001b[1mLoading tiledgrid encoding (compiling might take a while)...\u001b[0m\n",
            "\u001b[32m2023-03-09 14:52:28\u001b[0m \u001b[1m\tDone!\u001b[0m\n",
            "\u001b[32m2023-03-09 14:52:28\u001b[0m \u001b[1mLoading frequency encoding (compiling might take a while)...\u001b[0m\n",
            "\u001b[32m2023-03-09 14:53:43\u001b[0m \u001b[1m\tDone!\u001b[0m\n",
            "\u001b[32m2023-03-09 14:53:48\u001b[0m \u001b[1mLoaded grid NeRF, #parameters: 12249145\u001b[0m\n",
            "\u001b[32m2023-03-09 14:53:48\u001b[0m \u001b[1mNeRFNetwork(\n",
            "  (encoder): GridEncoder: input_dim=3 num_levels=16 level_dim=2 resolution=16 -> 2048 per_level_scale=1.3819 params=(6119864, 2) gridtype=tiled align_corners=False\n",
            "  (sigma_net): MLP(\n",
            "    (net): ModuleList(\n",
            "      (0): Linear(in_features=32, out_features=64, bias=True)\n",
            "      (1): Linear(in_features=64, out_features=64, bias=True)\n",
            "      (2): Linear(in_features=64, out_features=5, bias=True)\n",
            "    )\n",
            "  )\n",
            "  (encoder_bg): FreqEncoder: input_dim=3 degree=6 output_dim=39\n",
            "  (bg_net): MLP(\n",
            "    (net): ModuleList(\n",
            "      (0): Linear(in_features=39, out_features=64, bias=True)\n",
            "      (1): Linear(in_features=64, out_features=4, bias=True)\n",
            "    )\n",
            "  )\n",
            ")\u001b[0m\n",
            "\u001b[32m2023-03-09 14:53:48\u001b[0m \u001b[1mloaded hugging face access token from ./TOKEN!\u001b[0m\n",
            "\u001b[32m2023-03-09 14:53:48\u001b[0m \u001b[1mloading stable diffusion with CompVis/stable-diffusion-v1-4...\u001b[0m\n",
            "Downloading (…)on_pytorch_model.bin: 100% 335M/335M [00:01<00:00, 318MB/s]\n",
            "Downloading (…)main/vae/config.json: 100% 551/551 [00:00<00:00, 216kB/s]\n",
            "Downloading (…)olve/main/vocab.json: 100% 961k/961k [00:00<00:00, 2.22MB/s]\n",
            "Downloading (…)olve/main/merges.txt: 100% 525k/525k [00:00<00:00, 1.52MB/s]\n",
            "Downloading (…)cial_tokens_map.json: 100% 389/389 [00:00<00:00, 145kB/s]\n",
            "Downloading (…)okenizer_config.json: 100% 905/905 [00:00<00:00, 277kB/s]\n",
            "Downloading (…)lve/main/config.json: 100% 4.52k/4.52k [00:00<00:00, 1.72MB/s]\n",
            "Downloading pytorch_model.bin: 100% 1.71G/1.71G [00:07<00:00, 228MB/s]\n",
            "Downloading (…)on_pytorch_model.bin: 100% 3.44G/3.44G [00:23<00:00, 143MB/s]\n",
            "Downloading (…)ain/unet/config.json: 100% 743/743 [00:00<00:00, 247kB/s]\n",
            "\u001b[32m2023-03-09 14:54:35\u001b[0m \u001b[1m\t successfully loaded stable diffusion!\u001b[0m\n",
            "\u001b[32m2023-03-09 14:54:38\u001b[0m \u001b[1mSuccessfully initialized sand_castle\u001b[0m\n",
            "\u001b[32m2023-03-09 14:54:38\u001b[0m \u001b[1mStarting training ^_^\u001b[0m\n",
            "\u001b[32m2023-03-09 14:54:38\u001b[0m \u001b[1mEvaluating and saving model, iteration #0...\u001b[0m\n",
            "\u001b[32m2023-03-09 14:54:53\u001b[0m \u001b[1mDone!\u001b[0m\n",
            "\u001b[32m2023-03-09 14:55:27\u001b[0m \u001b[1mEvaluating and saving model, iteration #100...\u001b[0m\n",
            "\u001b[32m2023-03-09 14:55:45\u001b[0m \u001b[1mDone!\u001b[0m\n",
            "\u001b[32m2023-03-09 14:56:21\u001b[0m \u001b[1mEvaluating and saving model, iteration #200...\u001b[0m\n",
            "\u001b[32m2023-03-09 14:56:39\u001b[0m \u001b[1mDone!\u001b[0m\n",
            "\u001b[32m2023-03-09 14:57:15\u001b[0m \u001b[1mEvaluating and saving model, iteration #300...\u001b[0m\n",
            "\u001b[32m2023-03-09 14:57:33\u001b[0m \u001b[1mDone!\u001b[0m\n",
            "\u001b[32m2023-03-09 14:58:10\u001b[0m \u001b[1mEvaluating and saving model, iteration #400...\u001b[0m\n",
            "\u001b[32m2023-03-09 14:58:30\u001b[0m \u001b[1mDone!\u001b[0m\n",
            "\u001b[32m2023-03-09 14:59:07\u001b[0m \u001b[1mEvaluating and saving model, iteration #500...\u001b[0m\n",
            "\u001b[32m2023-03-09 14:59:29\u001b[0m \u001b[1mDone!\u001b[0m\n",
            "\u001b[32m2023-03-09 15:00:07\u001b[0m \u001b[1mEvaluating and saving model, iteration #600...\u001b[0m\n",
            "\u001b[32m2023-03-09 15:00:29\u001b[0m \u001b[1mDone!\u001b[0m\n",
            "\u001b[32m2023-03-09 15:01:05\u001b[0m \u001b[1mEvaluating and saving model, iteration #700...\u001b[0m\n",
            "\u001b[32m2023-03-09 15:01:24\u001b[0m \u001b[1mDone!\u001b[0m\n",
            "\u001b[32m2023-03-09 15:02:01\u001b[0m \u001b[1mEvaluating and saving model, iteration #800...\u001b[0m\n",
            "\u001b[32m2023-03-09 15:02:18\u001b[0m \u001b[1mDone!\u001b[0m\n",
            "\u001b[32m2023-03-09 15:02:55\u001b[0m \u001b[1mEvaluating and saving model, iteration #900...\u001b[0m\n",
            "\u001b[32m2023-03-09 15:03:14\u001b[0m \u001b[1mDone!\u001b[0m\n",
            "\u001b[32m2023-03-09 15:03:50\u001b[0m \u001b[1mEvaluating and saving model, iteration #1000...\u001b[0m\n",
            "\u001b[32m2023-03-09 15:04:08\u001b[0m \u001b[1mDone!\u001b[0m\n",
            "\u001b[32m2023-03-09 15:04:48\u001b[0m \u001b[1mEvaluating and saving model, iteration #1100...\u001b[0m\n",
            "\u001b[32m2023-03-09 15:05:08\u001b[0m \u001b[1mDone!\u001b[0m\n",
            "\u001b[32m2023-03-09 15:05:45\u001b[0m \u001b[1mEvaluating and saving model, iteration #1200...\u001b[0m\n",
            "\u001b[32m2023-03-09 15:06:04\u001b[0m \u001b[1mDone!\u001b[0m\n",
            "\u001b[32m2023-03-09 15:06:41\u001b[0m \u001b[1mEvaluating and saving model, iteration #1300...\u001b[0m\n",
            "\u001b[32m2023-03-09 15:07:00\u001b[0m \u001b[1mDone!\u001b[0m\n",
            "\u001b[32m2023-03-09 15:07:37\u001b[0m \u001b[1mEvaluating and saving model, iteration #1400...\u001b[0m\n",
            "\u001b[32m2023-03-09 15:07:54\u001b[0m \u001b[1mDone!\u001b[0m\n",
            "\u001b[32m2023-03-09 15:08:32\u001b[0m \u001b[1mEvaluating and saving model, iteration #1500...\u001b[0m\n",
            "\u001b[32m2023-03-09 15:08:49\u001b[0m \u001b[1mDone!\u001b[0m\n",
            "\u001b[32m2023-03-09 15:09:26\u001b[0m \u001b[1mEvaluating and saving model, iteration #1600...\u001b[0m\n",
            "\u001b[32m2023-03-09 15:09:43\u001b[0m \u001b[1mDone!\u001b[0m\n",
            "\u001b[32m2023-03-09 15:10:19\u001b[0m \u001b[1mEvaluating and saving model, iteration #1700...\u001b[0m\n",
            "\u001b[32m2023-03-09 15:10:36\u001b[0m \u001b[1mDone!\u001b[0m\n",
            "\u001b[32m2023-03-09 15:11:12\u001b[0m \u001b[1mEvaluating and saving model, iteration #1800...\u001b[0m\n",
            "\u001b[32m2023-03-09 15:11:29\u001b[0m \u001b[1mDone!\u001b[0m\n",
            "\u001b[32m2023-03-09 15:12:05\u001b[0m \u001b[1mEvaluating and saving model, iteration #1900...\u001b[0m\n",
            "\u001b[32m2023-03-09 15:12:22\u001b[0m \u001b[1mDone!\u001b[0m\n",
            "\u001b[32m2023-03-09 15:13:00\u001b[0m \u001b[1mEvaluating and saving model, iteration #2000...\u001b[0m\n",
            "\u001b[32m2023-03-09 15:13:16\u001b[0m \u001b[1mDone!\u001b[0m\n",
            "\u001b[32m2023-03-09 15:13:54\u001b[0m \u001b[1mEvaluating and saving model, iteration #2100...\u001b[0m\n",
            "\u001b[32m2023-03-09 15:14:11\u001b[0m \u001b[1mDone!\u001b[0m\n",
            "\u001b[32m2023-03-09 15:14:49\u001b[0m \u001b[1mEvaluating and saving model, iteration #2200...\u001b[0m\n",
            "\u001b[32m2023-03-09 15:15:07\u001b[0m \u001b[1mDone!\u001b[0m\n",
            "\u001b[32m2023-03-09 15:15:43\u001b[0m \u001b[1mEvaluating and saving model, iteration #2300...\u001b[0m\n",
            "\u001b[32m2023-03-09 15:16:01\u001b[0m \u001b[1mDone!\u001b[0m\n",
            "\u001b[32m2023-03-09 15:16:36\u001b[0m \u001b[1mEvaluating and saving model, iteration #2400...\u001b[0m\n",
            "\u001b[32m2023-03-09 15:16:52\u001b[0m \u001b[1mDone!\u001b[0m\n",
            "\u001b[32m2023-03-09 15:17:32\u001b[0m \u001b[1mEvaluating and saving model, iteration #2500...\u001b[0m\n",
            "\u001b[32m2023-03-09 15:17:48\u001b[0m \u001b[1mDone!\u001b[0m\n",
            "\u001b[32m2023-03-09 15:18:22\u001b[0m \u001b[1mEvaluating and saving model, iteration #2600...\u001b[0m\n",
            "\u001b[32m2023-03-09 15:18:38\u001b[0m \u001b[1mDone!\u001b[0m\n",
            "\u001b[32m2023-03-09 15:19:14\u001b[0m \u001b[1mEvaluating and saving model, iteration #2700...\u001b[0m\n",
            "\u001b[32m2023-03-09 15:19:30\u001b[0m \u001b[1mDone!\u001b[0m\n",
            "\u001b[32m2023-03-09 15:20:05\u001b[0m \u001b[1mEvaluating and saving model, iteration #2800...\u001b[0m\n",
            "\u001b[32m2023-03-09 15:20:21\u001b[0m \u001b[1mDone!\u001b[0m\n",
            "\u001b[32m2023-03-09 15:20:57\u001b[0m \u001b[1mEvaluating and saving model, iteration #2900...\u001b[0m\n",
            "\u001b[32m2023-03-09 15:21:13\u001b[0m \u001b[1mDone!\u001b[0m\n",
            "\u001b[32m2023-03-09 15:21:51\u001b[0m \u001b[1mEvaluating and saving model, iteration #3000...\u001b[0m\n",
            "\u001b[32m2023-03-09 15:22:07\u001b[0m \u001b[1mDone!\u001b[0m\n",
            "\u001b[32m2023-03-09 15:22:41\u001b[0m \u001b[1mEvaluating and saving model, iteration #3100...\u001b[0m\n",
            "\u001b[32m2023-03-09 15:22:58\u001b[0m \u001b[1mDone!\u001b[0m\n",
            "\u001b[32m2023-03-09 15:23:33\u001b[0m \u001b[1mEvaluating and saving model, iteration #3200...\u001b[0m\n",
            "\u001b[32m2023-03-09 15:23:49\u001b[0m \u001b[1mDone!\u001b[0m\n",
            "\u001b[32m2023-03-09 15:24:29\u001b[0m \u001b[1mEvaluating and saving model, iteration #3300...\u001b[0m\n",
            "\u001b[32m2023-03-09 15:24:46\u001b[0m \u001b[1mDone!\u001b[0m\n",
            "\u001b[32m2023-03-09 15:25:21\u001b[0m \u001b[1mEvaluating and saving model, iteration #3400...\u001b[0m\n",
            "\u001b[32m2023-03-09 15:25:38\u001b[0m \u001b[1mDone!\u001b[0m\n",
            "\u001b[32m2023-03-09 15:26:16\u001b[0m \u001b[1mEvaluating and saving model, iteration #3500...\u001b[0m\n",
            "\u001b[32m2023-03-09 15:26:32\u001b[0m \u001b[1mDone!\u001b[0m\n",
            "\u001b[32m2023-03-09 15:27:09\u001b[0m \u001b[1mEvaluating and saving model, iteration #3600...\u001b[0m\n",
            "\u001b[32m2023-03-09 15:27:24\u001b[0m \u001b[1mDone!\u001b[0m\n",
            "\u001b[32m2023-03-09 15:28:00\u001b[0m \u001b[1mEvaluating and saving model, iteration #3700...\u001b[0m\n",
            "\u001b[32m2023-03-09 15:28:16\u001b[0m \u001b[1mDone!\u001b[0m\n",
            "\u001b[32m2023-03-09 15:28:53\u001b[0m \u001b[1mEvaluating and saving model, iteration #3800...\u001b[0m\n",
            "\u001b[32m2023-03-09 15:29:09\u001b[0m \u001b[1mDone!\u001b[0m\n",
            "\u001b[32m2023-03-09 15:29:46\u001b[0m \u001b[1mEvaluating and saving model, iteration #3900...\u001b[0m\n",
            "\u001b[32m2023-03-09 15:30:01\u001b[0m \u001b[1mDone!\u001b[0m\n",
            "\u001b[32m2023-03-09 15:30:39\u001b[0m \u001b[1mEvaluating and saving model, iteration #4000...\u001b[0m\n",
            "\u001b[32m2023-03-09 15:30:55\u001b[0m \u001b[1mDone!\u001b[0m\n",
            "\u001b[32m2023-03-09 15:31:32\u001b[0m \u001b[1mEvaluating and saving model, iteration #4100...\u001b[0m\n",
            "\u001b[32m2023-03-09 15:31:47\u001b[0m \u001b[1mDone!\u001b[0m\n",
            "\u001b[32m2023-03-09 15:32:23\u001b[0m \u001b[1mEvaluating and saving model, iteration #4200...\u001b[0m\n",
            "\u001b[32m2023-03-09 15:32:38\u001b[0m \u001b[1mDone!\u001b[0m\n",
            "\u001b[32m2023-03-09 15:33:13\u001b[0m \u001b[1mEvaluating and saving model, iteration #4300...\u001b[0m\n",
            "\u001b[32m2023-03-09 15:33:28\u001b[0m \u001b[1mDone!\u001b[0m\n",
            "\u001b[32m2023-03-09 15:34:07\u001b[0m \u001b[1mEvaluating and saving model, iteration #4400...\u001b[0m\n",
            "\u001b[32m2023-03-09 15:34:24\u001b[0m \u001b[1mDone!\u001b[0m\n",
            "\u001b[32m2023-03-09 15:35:03\u001b[0m \u001b[1mEvaluating and saving model, iteration #4500...\u001b[0m\n",
            "\u001b[32m2023-03-09 15:35:18\u001b[0m \u001b[1mDone!\u001b[0m\n",
            "\u001b[32m2023-03-09 15:35:55\u001b[0m \u001b[1mEvaluating and saving model, iteration #4600...\u001b[0m\n",
            "\u001b[32m2023-03-09 15:36:10\u001b[0m \u001b[1mDone!\u001b[0m\n",
            "\u001b[32m2023-03-09 15:36:46\u001b[0m \u001b[1mEvaluating and saving model, iteration #4700...\u001b[0m\n",
            "\u001b[32m2023-03-09 15:37:01\u001b[0m \u001b[1mDone!\u001b[0m\n",
            "\u001b[32m2023-03-09 15:37:40\u001b[0m \u001b[1mEvaluating and saving model, iteration #4800...\u001b[0m\n",
            "\u001b[32m2023-03-09 15:37:55\u001b[0m \u001b[1mDone!\u001b[0m\n",
            "\u001b[32m2023-03-09 15:38:30\u001b[0m \u001b[1mEvaluating and saving model, iteration #4900...\u001b[0m\n",
            "\u001b[32m2023-03-09 15:38:46\u001b[0m \u001b[1mDone!\u001b[0m\n",
            "\u001b[32m2023-03-09 15:39:22\u001b[0m \u001b[1mEvaluating and saving model, iteration #5000...\u001b[0m\n",
            "\u001b[32m2023-03-09 15:39:38\u001b[0m \u001b[1mDone!\u001b[0m\n",
            "\u001b[32m2023-03-09 15:39:38\u001b[0m \u001b[1mFinished Training ^_^\u001b[0m\n",
            "\u001b[32m2023-03-09 15:39:38\u001b[0m \u001b[1mEvaluating the last model...\u001b[0m\n",
            "\u001b[32m2023-03-09 15:39:38\u001b[0m \u001b[1mEvaluating and saving model, iteration #5000...\u001b[0m\n",
            "100% 5000/5000 [44:44<00:00,  3.00it/s]Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/imageio/plugins/ffmpeg.py\", line 59, in _get_ffmpeg_api\n",
            "    import imageio_ffmpeg\n",
            "ModuleNotFoundError: No module named 'imageio_ffmpeg'\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n",
            "    return _run_code(code, main_globals, None,\n",
            "  File \"/usr/lib/python3.9/runpy.py\", line 87, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/content/latent-nerf/scripts/train_latent_nerf.py\", line 17, in <module>\n",
            "    main()\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/pyrallis/argparsing.py\", line 158, in wrapper_inner\n",
            "    response = fn(cfg, *args, **kwargs)\n",
            "  File \"/content/latent-nerf/scripts/train_latent_nerf.py\", line 14, in main\n",
            "    trainer.train()\n",
            "  File \"/content/latent-nerf/src/latent_nerf/training/trainer.py\", line 158, in train\n",
            "    self.full_eval()\n",
            "  File \"/content/latent-nerf/src/latent_nerf/training/trainer.py\", line 203, in full_eval\n",
            "    self.evaluate(self.dataloaders['val_large'], self.final_renders_path, save_as_video=True)\n",
            "  File \"/content/latent-nerf/src/latent_nerf/training/trainer.py\", line 197, in evaluate\n",
            "    dump_vid(all_preds, 'rgb')\n",
            "  File \"/content/latent-nerf/src/latent_nerf/training/trainer.py\", line 193, in <lambda>\n",
            "    dump_vid = lambda video, name: imageio.mimsave(save_path / f\"{self.train_step}_{name}.mp4\", video, fps=25,\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/imageio/core/functions.py\", line 397, in mimwrite\n",
            "    writer = get_writer(uri, format, \"I\", **kwargs)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/imageio/core/functions.py\", line 231, in get_writer\n",
            "    return format.get_writer(request)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/imageio/core/format.py\", line 185, in get_writer\n",
            "    return self.Writer(self, request)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/imageio/core/format.py\", line 221, in __init__\n",
            "    self._open(**self.request.kwargs.copy())\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/imageio/plugins/ffmpeg.py\", line 525, in _open\n",
            "    self._ffmpeg_api = _get_ffmpeg_api()\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/imageio/plugins/ffmpeg.py\", line 61, in _get_ffmpeg_api\n",
            "    raise ImportError(\n",
            "ImportError: To use the imageio ffmpeg plugin you need to 'pip install imageio-ffmpeg'\n",
            "100% 5000/5000 [46:53<00:00,  1.78it/s]\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "orig_nbformat": 4,
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "gpuClass": "standard",
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}